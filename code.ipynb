{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Music Chords Generation using LSTM networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\40864\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Seed value\n",
    "seed = 1988\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed)\n",
    "\n",
    "import random\n",
    "random.seed(seed)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(seed)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "from keras import backend as bk\n",
    "conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "session = tf.Session(graph=tf.get_default_graph(), config=conf)\n",
    "bk.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import EarlyStopping\n",
    "from xml.dom.minidom import parse, parseString\n",
    "from xml.parsers.expat import ExpatError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_len = 8\n",
    "pred_len = 1\n",
    "vocab_size = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =r'.'\n",
    "genres = list()\n",
    "\n",
    "\n",
    "for sub_path in glob.iglob(path + '/hooktheory_dataset/datasets/xml/**/**/**/'):    \n",
    "    \n",
    "    \n",
    "    file = sub_path + '/song_info.json'\n",
    "    \n",
    "    \n",
    "    with open(file,'r') as load_f:\n",
    "        load_dict = json.load(load_f)\n",
    "\n",
    "        for genre in load_dict['genres']:\n",
    "            \n",
    "            if genre not in genres:\n",
    "                genres.append(genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Metal', 'Rock', 'Pop', 'Singer-Songwriter', 'Alternative', 'Indie', 'House', 'Soundtrack', 'Hip-Hop/Rap', 'R & B', 'Dance', 'Electronic', 'Holiday', 'Worship', 'Classical', 'Video Game', 'Reggae', 'Experimental', 'Jazz', 'Blues', 'Soul', 'K-pop', \"Children's\", 'Vocal', 'J-Pop', 'Techno', 'World', 'Alt-Country', 'Disney', 'Folk', 'Punk', 'Country', 'Latin']"
     ]
    }
   ],
   "source": [
    "print(genres, end = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_genres = ['Metal', 'Rock', 'Pop', 'Singer-Songwriter', 'Alternative', 'Indie', 'House', 'Dance', 'Electronic', 'Video Game', 'Reggae',\n",
    "           'Experimental', 'Jazz', 'Blues', 'Soul', 'K-pop', 'J-Pop', 'Techno', 'Alt-Country', 'Folk', 'Punk', 'Country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(select_genres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =r'.'\n",
    "sequences = list()\n",
    "next_chord = list()\n",
    "count_songs = 0\n",
    "\n",
    "for sub_path in glob.iglob(path + '/hooktheory_dataset/datasets/xml/**/**/**/'):    \n",
    "    \n",
    "    \n",
    "    file = sub_path + '/song_info.json'\n",
    "    \n",
    "    \n",
    "    with open(file,'r') as load_f:\n",
    "        load_dict = json.load(load_f)\n",
    "\n",
    "        for genre in load_dict['genres']:\n",
    "            \n",
    "            if genre in select_genres:\n",
    "            \n",
    "                count_songs += 1\n",
    "\n",
    "                sections = load_dict['section']\n",
    "\n",
    "                chords = []\n",
    "\n",
    "                for section in sections:\n",
    "\n",
    "                    file = sub_path + '/' + section + '.xml'\n",
    "                    try:\n",
    "                        dom = parse(file)\n",
    "                        notes = dom.getElementsByTagName(\"chord\")\n",
    "\n",
    "                        for note in notes:\n",
    "                            if note.getElementsByTagName(\"sd\")[0].childNodes[0].nodeValue != 'rest':\n",
    "                                chords.append(int(note.getElementsByTagName(\"sd\")[0].childNodes[0].nodeValue)-1)\n",
    "\n",
    "                    except ExpatError:\n",
    "                        pass\n",
    "\n",
    "                    continue\n",
    "\n",
    "                for i in range(input_len, len(chords) - pred_len + 1):\n",
    "                    sequences.append(chords[i - input_len : i])\n",
    "                    next_chord.append(chords[i]) \n",
    "                    \n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sequences\n",
    "b = next_chord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111478"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5720"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(a)\n",
    "b = np.array(b)\n",
    "X, y = a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use one hot encoding to shift numeral to vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [to_categorical(x, num_classes=vocab_size) for x in X]\n",
    "X = np.array(X)\n",
    "y = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Split the dataset into train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(a) * 0.70)\n",
    "test_size = len(a) - train_size\n",
    "train_X, test_X = X[0:train_size], X[train_size:len(X)]\n",
    "train_y, test_y = y[0:train_size], y[train_size:len(X)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the LSTM network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 8, 128)            69632     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 202,119\n",
      "Trainable params: 202,119\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences=True, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(train_y.shape[1], activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the LSTM network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 78034 samples, validate on 33444 samples\n",
      "Epoch 1/100\n",
      " - 89s - loss: 1.5770 - acc: 0.4059 - val_loss: 1.4888 - val_acc: 0.4627\n",
      "Epoch 2/100\n",
      " - 85s - loss: 1.4212 - acc: 0.4957 - val_loss: 1.4547 - val_acc: 0.4818\n",
      "Epoch 3/100\n",
      " - 90s - loss: 1.3679 - acc: 0.5187 - val_loss: 1.4424 - val_acc: 0.4922\n",
      "Epoch 4/100\n",
      " - 90s - loss: 1.3329 - acc: 0.5339 - val_loss: 1.4355 - val_acc: 0.4923\n",
      "Epoch 5/100\n",
      " - 91s - loss: 1.3036 - acc: 0.5460 - val_loss: 1.4380 - val_acc: 0.4923\n",
      "Epoch 6/100\n",
      " - 89s - loss: 1.2309 - acc: 0.5705 - val_loss: 1.4389 - val_acc: 0.5006\n",
      "Epoch 7/100\n",
      " - 88s - loss: 1.1930 - acc: 0.5858 - val_loss: 1.4497 - val_acc: 0.4970\n",
      "Epoch 8/100\n",
      " - 86s - loss: 1.1349 - acc: 0.6043 - val_loss: 1.4725 - val_acc: 0.4969\n",
      "Epoch 9/100\n",
      " - 88s - loss: 1.0894 - acc: 0.6218 - val_loss: 1.4947 - val_acc: 0.4947\n",
      "Time elapsed: 796\n"
     ]
    }
   ],
   "source": [
    "# 8 for 1\n",
    "start = time.time()\n",
    "\n",
    "opt = optimizers.adam(lr=0.01)\n",
    "rlrop = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=1)\n",
    "estop = EarlyStopping(monitor='val_acc', min_delta=0.0001, patience=3)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "model.fit(train_X, train_y, batch_size=64, epochs=100, verbose=2, callbacks=[rlrop, estop], validation_data = (test_X, test_y))\n",
    "\n",
    "end = time.time()\n",
    "print('Time elapsed: %d'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a function to select one of the states by sampling a state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(a):\n",
    "\n",
    "    return np.argmax(np.random.multinomial(1, a, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a function to transform the numerals into symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_dic = {1:'C', 2:'Db', 3:'D', 4:'Eb', 5:'E', 6:'F', 7:'#F', 8:'G', 9:'Ab', 10:'A', 11:'bB', 12:'B'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(output):\n",
    "    if scale == 'major':\n",
    "        for n in range(len(output)):\n",
    "            if output[n] == 1:\n",
    "                output[n] = key_dic[key_idx]\n",
    "            elif output[n] == 2 or output[n] == 3:\n",
    "                if key_idx + output[n] * 2 - 2 <= 12:\n",
    "                    output[n] = key_dic[key_idx + output[n] * 2 - 2] + 'm'\n",
    "                else:\n",
    "                    output[n] = key_dic[key_idx + output[n] * 2 - 2 -12] + 'm'\n",
    "            elif output[n] == 4 or output[n] == 5:\n",
    "                if key_idx + output[n] * 2 - 3 <= 12:\n",
    "                    output[n] = key_dic[key_idx + output[n] * 2 - 3]\n",
    "                else:\n",
    "                    output[n] = key_dic[key_idx + output[n] * 2 - 3 - 12]\n",
    "            elif output[n] == 6:\n",
    "                if key_idx + output[n] * 2 - 3 <= 12:\n",
    "                    output[n] = key_dic[key_idx + output[n] * 2 - 3] + 'm'\n",
    "                else:\n",
    "                    output[n] = key_dic[key_idx + output[n] * 2 - 3 - 12] + 'm'\n",
    "            else:\n",
    "                if key_idx + output[n] * 2 - 3 <=12:\n",
    "                    output[n] = key_dic[key_idx + output[n] * 2 - 3] + 'dim'\n",
    "                else:\n",
    "                    output[n] = key_dic[key_idx + output[n] * 2 - 3 - 12] + 'dim'\n",
    "\n",
    "    else:\n",
    "         for n in range(len(output)):\n",
    "            if output[n] == 1:\n",
    "                output[n] = key_dic[key_idx] + 'm'\n",
    "            elif output[n] == 2:\n",
    "                if key_idx + 2 <= 12:\n",
    "                    output[n] = key_dic[key_idx + 2] + 'dim'\n",
    "                else:\n",
    "                    output[n] = key_dic[key_idx + 2 - 12] + 'dim'\n",
    "            elif output[n] == 3:\n",
    "                if key_idx + 2 < 12:\n",
    "                    output[n] = key_dic[key_idx + 3]\n",
    "                else:\n",
    "                    output[n] = key_dic[key_idx + 3 - 12]    \n",
    "            elif output[n] == 4 or output[n] == 5:\n",
    "                if key_idx + output[n] * 2 - 3 <= 12:\n",
    "                    output[n] = key_dic[key_idx + output[n] * 2 - 3] + 'm'\n",
    "                else:\n",
    "                    output[n] = key_dic[key_idx + output[n] * 2 - 3 - 12] + 'm'\n",
    "            elif output[n] == 6:\n",
    "                if key_idx + 8 <= 12:\n",
    "                    output[n] = key_dic[key_idx + 8]\n",
    "                else:\n",
    "                    output[n] = key_dic[key_idx + 8 - 12]\n",
    "            else: \n",
    "                if key_idx + 10 <= 12:\n",
    "                    output[n] = key_dic[key_idx + 10]\n",
    "                else:\n",
    "                    output[n] = key_dic[key_idx + 10 - 12]\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 4, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2]\n",
      "[3, 6, 5, 4, 3, 3, 2, 4, 5, 1, 5, 6]\n",
      "[5, 2, 6, 6, 3, 5, 4, 6, 5, 5, 4, 5]\n",
      "[6, 6, 4, 4, 4, 4, 4, 5, 5, 5, 5, 1]\n"
     ]
    }
   ],
   "source": [
    "outputs = list()\n",
    "for i in range(4):   \n",
    "    \n",
    "    input = [list(np.random.randint(low = 0, high = 7,size = 8))]\n",
    "    \n",
    "    output_len = 12\n",
    "    output = list()\n",
    "\n",
    "    for j in range(output_len):    \n",
    "        encoded = to_categorical(input, num_classes=7)\n",
    "        y_pred = model.predict(encoded, verbose=0)[0]\n",
    "        next_chord = sample(y_pred)\n",
    "        output.append(next_chord + 1)\n",
    "        input[0] = input[0][1:]\n",
    "        input[0].append(next_chord)\n",
    "\n",
    "    outputs.append(output)\n",
    "    \n",
    "    print(output, end = '')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'A', '#Fm', '#Fm', 'E', 'E', '#Fm', '#Fm', 'E', 'E', '#Fm', '#Fm']\n"
     ]
    }
   ],
   "source": [
    "key_idx = 5\n",
    "key = key_dic[key_idx]\n",
    "scale = 'major'\n",
    "o = list(outputs[0])\n",
    "\n",
    "transform(o)\n",
    "print(o, end = '')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Em', 'Am', 'G', 'F', 'Em', 'Em', 'Dm', 'F', 'G', 'C', 'G', 'Am']\n"
     ]
    }
   ],
   "source": [
    "key_idx = 1\n",
    "key = key_dic[key_idx]\n",
    "scale = 'major'\n",
    "o = list(outputs[1])\n",
    "\n",
    "transform(o)\n",
    "print(o, end = '')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#F', 'Dbm', 'Abm', 'Abm', 'Ebm', '#F', 'E', 'Abm', '#F', '#F', 'E', '#F']\n"
     ]
    }
   ],
   "source": [
    "key_idx = 12\n",
    "key = key_dic[key_idx]\n",
    "scale = 'major'\n",
    "o = list(outputs[2])\n",
    "\n",
    "transform(o)\n",
    "print(o, end = '')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Am', 'Am', 'F', 'F', 'F', 'F', 'F', 'G', 'G', 'G', 'G', 'C']\n"
     ]
    }
   ],
   "source": [
    "key_idx = 1\n",
    "key = key_dic[key_idx]\n",
    "scale = 'major'\n",
    "o = list(outputs[3])\n",
    "\n",
    "transform(o)\n",
    "print(o, end = '')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encourages the diversity of prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(a):\n",
    "    a = np.log(a) / 1.2\n",
    "    a = np.exp(a) / np.sum(np.exp(a))\n",
    "    return np.argmax(np.random.multinomial(1, a, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 3, 7, 4, 3, 5, 6, 3, 5, 4, 3, 6]\n",
      "[1, 6, 7, 7, 1, 7, 6, 1, 7, 7, 6, 1]\n",
      "[1, 1, 1, 5, 5, 5, 4, 4, 1, 5, 6, 6]\n",
      "[1, 3, 1, 3, 2, 5, 6, 1, 3, 2, 7, 6]\n"
     ]
    }
   ],
   "source": [
    "outputs2 = list()\n",
    "for i in range(4):   \n",
    "    \n",
    "    input = [list(np.random.randint(low = 0, high = 7,size = 8))]\n",
    "    \n",
    "    output_len = 12\n",
    "    output = list()\n",
    "\n",
    "    for j in range(output_len):    \n",
    "        encoded = to_categorical(input, num_classes=7)\n",
    "        y_pred = model.predict(encoded, verbose=0)[0]\n",
    "        next_chord = sample(y_pred)\n",
    "        output.append(next_chord + 1)\n",
    "        input[0] = input[0][1:]\n",
    "        input[0].append(next_chord)\n",
    "\n",
    "    outputs2.append(output)\n",
    "    \n",
    "    print(output, end = '')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dm', 'C', 'G', 'Dm', 'C', 'Em', 'F', 'C', 'Em', 'Dm', 'C', 'F']\n"
     ]
    }
   ],
   "source": [
    "key_idx = 10\n",
    "key = key_dic[key_idx]\n",
    "scale = 'minor'\n",
    "o = list(outputs2[0])\n",
    "\n",
    "transform(o)\n",
    "print(o, end = '')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cm', 'Ab', 'bB', 'bB', 'Cm', 'bB', 'Ab', 'Cm', 'bB', 'bB', 'Ab', 'Cm']\n"
     ]
    }
   ],
   "source": [
    "key_idx = 1\n",
    "key = key_dic[key_idx]\n",
    "scale = 'minor'\n",
    "o = list(outputs2[1])\n",
    "\n",
    "transform(o)\n",
    "print(o, end = '')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', 'C', 'C', 'G', 'G', 'G', 'F', 'F', 'C', 'G', 'Am', 'Am']\n"
     ]
    }
   ],
   "source": [
    "key_idx = 1\n",
    "key = key_dic[key_idx]\n",
    "scale = 'major'\n",
    "o = list(outputs2[2])\n",
    "\n",
    "transform(o)\n",
    "print(o, end = '')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'Dbm', 'A', 'Dbm', 'Bm', 'E', '#Fm', 'A', 'Dbm', 'Bm', 'Abdim', '#Fm']\n"
     ]
    }
   ],
   "source": [
    "key_idx = 10\n",
    "key = key_dic[key_idx]\n",
    "scale = 'major'\n",
    "o = list(outputs2[3])\n",
    "\n",
    "transform(o)\n",
    "print(o, end = '')\n",
    "print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
